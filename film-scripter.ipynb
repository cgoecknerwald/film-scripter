{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film-Scripter\n",
    "#### Claire Goeckner-Wald (181088)\n",
    "Github: https://github.com/cgoecknerwald/film-scripter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Usage: train.py filename/dirname [options]\n",
    "\n",
    "Options:           Description:                        Default:\n",
    "--model            Whether to use LSTM or GRU units    lstm\n",
    "--n_epochs         Number of epochs to train           65536\n",
    "--print_every      Log learning rate at this interval  100\n",
    "--hidden_size      Hidden size of GRU                  512\n",
    "--n_layers         Number of GRU layers                3\n",
    "--learning_rate    Learning rate                       0.01\n",
    "--chunk_len        Length of training chunks           256\n",
    "--batch_size       Number of examples per batch        128\n",
    "--dropout          Percentage dropout                  0.25\n",
    "--shuffle          Shuffle data                        store_true\n",
    "--cuda             Use CUDA                            store_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder `shakespeare` is a dataset of Shakespeare's plays. To train a model on the `shakespeare` folder, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, for a single textfile, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py shakespeare.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating\n",
    "\n",
    "<b>Note: all trained models were trained using CUDA, and so must be generated using CUDA, as well.</b> In addition, if you select a prediction length longer than your video RAM can handle, you will receive an out-of-memory error. Decrease your prediction length, and try again. For reference, ~200 characters was approximately the limit of per-call generation on a Nvidia GTX 1070.</b>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Usage: generate.py filename [options]\n",
    "\n",
    "Options:             Description:                            Default:\n",
    "-p, --prime_str      String to prime generation with         'A'\n",
    "-l, --predict_len    Length of prediction                    100\n",
    "-t, --temperature    Temperature (higher is more chaotic)    0.8\n",
    "--cuda               Use CUDA                                store_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a model called `shakespeare.pt`, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python generate.py shakespeare.pt --prime_str \"Where\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "The following models are included in the repository:\n",
    "\n",
    "- `cmumoviesummary_LSTM_NE65536_NL3_HS512.pt`: from CMU Movie Summary Corpus\n",
    "- `cornellmovielin_LSTM_NE65536_NL2_HS512.pt`: from Cornell Movie Lines Corpus\n",
    "- `londonascii_LSTM_NE8192_NL2_HS512.pt`: an example \"narration\" model based on the works of author Jack London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI\n",
    "The GitHub repository contains the basis for a GUI. Note that the website HTML must be manually modified to change models at this point in time, and the GUI can only be used to <i>generate</i> text from pretrained models, not to train models. To run the GUI server, first install Flask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3.6 -m pip install Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, start the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3.6 server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website is now locally-hosted at `http://127.0.0.1:5000/`.\n",
    "\n",
    "To shutdown, click the shutdown button, or visit: `http://127.0.0.1:5000/shutdown`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
